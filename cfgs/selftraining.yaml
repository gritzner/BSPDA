task: SelfTraining
output_path: tmp/selftraining/$0__$1
clear_output_path: True

AdaptedSegmentationDataset_params:
    path: $0/$1
    logits: tmp/logits.npz
    random_seed: 0
    patch_size: [256, 256]
    training_samples: 2500000
    normalization:
        independent_channels: none
        method: zscore
        fixed_depth_std: 30
    augmentation:
        <<: *augmentation-defaults
        at_test_time: False
    
ForestEnsemble_params:
    base_model: SegForestNet
    size: 3
    rng_seed: -2
    num_ignored_branches_during_training: 0

large_encoder: &large-encoder
    backbone: legacy_xception
    pretrained: True
    downsampling: 3
    resample_all_stages: False
    concatenate_stages: [2, 3]
    use_bias: False
    activation: ReLU
    normalization: BatchNorm2d
    dropout:
        channelwise: False
        
SegForestNet_params:
    <<: *SegForestNet-defaults
    encoder:
        <<: *large-encoder
    features:
        context: 0
        dct_sidechannel:
            type: 0 # 0 = disabled, otherwise see documentation of SciPy's dctn function
            num_features: 96
            num_res_blocks: 0
            dropout: 0.05
    decoder:
        num_blocks: 5
        context: 1
        intermediate_features: 128
        use_residual_blocks: True
        vq:
            type: [0, 0]
            codebook_size: 512
            normalized_length: 0
            loss_weights: [1, 1]
            one_hot_during_eval: True
            hard: True
            temperature:
                parameters: [epoch, epochs]
                func: min(epoch/5, 1)
                #func: 1-np.cos(0.5*np.pi*epoch/(epochs-1))
                value_range: [2, 0.1]
            loss_weight:
                parameters: [epoch, epochs]
                func: 0
                value_range: [.05, .05]
    trees:
        - num_features:
            shape: 44
            content: 40
          shape_to_content: 0
          graph: BSPTree(2, Line)
          classifier: []
          classifier_skip_from: 1
          classifier_context: 1
          one_tree_per_class: True
          dropout:
              shape: 0.5
              content: 0.5
    loss:
        cross_entropy: pixels
        ce_constant: 10
        distribution_metric: gini
        min_region_size: 4
        weights: [0.678, 0.19, 0.115, 0.017, 0]

SelfTraining_params:
    dataset: AdaptedSegmentationDataset
    model: ForestEnsemble
    model_weights: tmp/model.pt.xz
    shuffle_seed: -1
    epochs: 4
    num_samples_per_epoch: 25000
    mini_batch_size: 10
    pseudo_ground_truth:
        use_gini: False
        topk: 0
        threshold: $2
        dynamic_override:
            epoch_delay: 1337
            topk: 0
            threshold: 0.02
    min_valid_area_per_sample: 0.23
    active_learning:
        iterations: []
        random: False
        use_gini: True
        quantile: 0.5
    optimizer:
        type: SGD
        arguments:
            momentum: 0.969
            weight_decay: 0.00082
            dampening: 0.0000075
            nesterov: False
    learning_rate:
        max_value: $3
        min_value: 0.0016
        num_cycles: 1
        cycle_length_factor: 2
        num_iterations_factor: 1
    gradient_clipping: 3.25
    model_filename_extension: .pt.xz
    delete_irrelevant_models: True
    smoothing: 0.6
